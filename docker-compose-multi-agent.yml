# SolnAI Multi-Agent Deployment for NVIDIA Brev
# Organized by functional groups for efficient resource allocation

services:
  ##########################################
  # BASE INFRASTRUCTURE
  ##########################################
  
  base-python:
    build:
      context: ./base_python_docker
      dockerfile: Dockerfile
    image: solnai/base-python:latest
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
  
  archon:
    build:
      context: ./Archon
      dockerfile: Dockerfile
    image: solnai/archon:latest
    environment:
      API_KEY: your_api_key_here
      API_PORT: 8000
      API_HOST: 0.0.0.0
      GPU_MEMORY_FRACTION: 0.7
      LOG_LEVEL: INFO
    ports:
      - "8001:8000"
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 1G
        reservations:
          cpus: "0.25"
          memory: 512M
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 20s
      timeout: 10s
      retries: 5
      start_period: 40s
    networks:
      - agent_network
    restart: unless-stopped

  ##########################################
  # RESEARCH & CONTENT AGENTS - GPU: 0
  ##########################################
  
  general-researcher:
    build:
      context: ./general-researcher-agent
      dockerfile: Dockerfile
    image: solnai/general-researcher:latest
    environment:
      API_KEY: your_api_key_here
      API_PORT: 8010
      API_HOST: 0.0.0.0
      CUDA_VISIBLE_DEVICES: 0
      GPU_MEMORY_FRACTION: 0.4
    ports:
      - "8010:8010"
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 2G
        reservations:
          cpus: "0.25"
          memory: 1G
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
              device_ids: ["0"]
    networks:
      - agent_network
    restart: unless-stopped
    depends_on:
      - base-python

  advanced-researcher:
    build:
      context: ./pydantic-ai-advanced-researcher
      dockerfile: Dockerfile
    image: solnai/advanced-researcher:latest
    environment:
      API_KEY: your_api_key_here
      API_PORT: 8011
      API_HOST: 0.0.0.0
      CUDA_VISIBLE_DEVICES: 0
      GPU_MEMORY_FRACTION: 0.4
    ports:
      - "8011:8011"
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 2G
        reservations:
          cpus: "0.25"
          memory: 1G
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
              device_ids: ["0"]
    networks:
      - agent_network
    restart: unless-stopped
    depends_on:
      - base-python

  content-creator:
    build:
      context: ./linkedin-x-blog-content-creator
      dockerfile: Dockerfile
    image: solnai/content-creator:latest
    environment:
      API_KEY: your_api_key_here
      API_PORT: 8012
      API_HOST: 0.0.0.0
      CUDA_VISIBLE_DEVICES: 0
      GPU_MEMORY_FRACTION: 0.3
    ports:
      - "8012:8012"
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 2G
        reservations:
          cpus: "0.25"
          memory: 1G
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
              device_ids: ["0"]
    networks:
      - agent_network
    restart: unless-stopped
    depends_on:
      - base-python

  ##########################################
  # VIDEO & MEDIA PROCESSING - GPU: 1
  ##########################################
  
  youtube-summary:
    build:
      context: ./youtube-summary-agent
      dockerfile: Dockerfile
    image: solnai/youtube-summary:latest
    environment:
      API_KEY: your_api_key_here
      API_PORT: 8020
      API_HOST: 0.0.0.0
      CUDA_VISIBLE_DEVICES: 1
      GPU_MEMORY_FRACTION: 0.4
    ports:
      - "8020:8020"
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 2G
        reservations:
          cpus: "0.25"
          memory: 1G
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
              device_ids: ["1"]
    networks:
      - agent_network
    restart: unless-stopped
    depends_on:
      - base-python

  youtube-educator:
    build:
      context: ./youtube-educator-plus-agent
      dockerfile: Dockerfile
    image: solnai/youtube-educator:latest
    environment:
      API_KEY: your_api_key_here
      API_PORT: 8021
      API_HOST: 0.0.0.0
      CUDA_VISIBLE_DEVICES: 1
      GPU_MEMORY_FRACTION: 0.4
    ports:
      - "8021:8021"
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 2G
        reservations:
          cpus: "0.25"
          memory: 1G
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
              device_ids: ["1"]
    networks:
      - agent_network
    restart: unless-stopped
    depends_on:
      - base-python

  streambuzz:
    build:
      context: ./streambuzz-agent
      dockerfile: Dockerfile
    image: solnai/streambuzz:latest
    environment:
      API_KEY: your_api_key_here
      API_PORT: 8022
      API_HOST: 0.0.0.0
      CUDA_VISIBLE_DEVICES: 1
      GPU_MEMORY_FRACTION: 0.3
    ports:
      - "8022:8022"
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 2G
        reservations:
          cpus: "0.25"
          memory: 1G
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
              device_ids: ["1"]
    networks:
      - agent_network
    restart: unless-stopped
    depends_on:
      - base-python

  ##########################################
  # TECHNICAL & DEVELOPMENT - GPU: 2
  ##########################################
  
  github-agent:
    build:
      context: ./pydantic-github-agent
      dockerfile: Dockerfile
    image: solnai/github-agent:latest
    environment:
      API_KEY: your_api_key_here
      API_PORT: 8030
      API_HOST: 0.0.0.0
      CUDA_VISIBLE_DEVICES: 2
      GPU_MEMORY_FRACTION: 0.4
      GITHUB_TOKEN: your_github_token_here
    ports:
      - "8030:8030"
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 2G
        reservations:
          cpus: "0.25"
          memory: 1G
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
              device_ids: ["2"]
    networks:
      - agent_network
    restart: unless-stopped
    depends_on:
      - base-python

  tech-stack-expert:
    build:
      context: ./tech-stack-expert
      dockerfile: Dockerfile
    image: solnai/tech-stack-expert:latest
    environment:
      API_KEY: your_api_key_here
      API_PORT: 8031
      API_HOST: 0.0.0.0
      CUDA_VISIBLE_DEVICES: 2
      GPU_MEMORY_FRACTION: 0.3
    ports:
      - "8031:8031"
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 2G
        reservations:
          cpus: "0.25"
          memory: 1G
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
              device_ids: ["2"]
    networks:
      - agent_network
    restart: unless-stopped
    depends_on:
      - base-python

  openai-sdk-agent:
    build:
      context: ./openai-sdk-agent
      dockerfile: Dockerfile
    image: solnai/openai-sdk-agent:latest
    environment:
      API_KEY: your_api_key_here
      API_PORT: 8032
      API_HOST: 0.0.0.0
      CUDA_VISIBLE_DEVICES: 2
      GPU_MEMORY_FRACTION: 0.3
    ports:
      - "8032:8032"
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 2G
        reservations:
          cpus: "0.25"
          memory: 1G
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
              device_ids: ["2"]
    networks:
      - agent_network
    restart: unless-stopped
    depends_on:
      - base-python

  ##########################################
  # BUSINESS & INDUSTRY - GPU: 3
  ##########################################
  
  lead-generator:
    build:
      context: ./lead-generator-agent
      dockerfile: Dockerfile
    image: solnai/lead-generator:latest
    environment:
      API_KEY: your_api_key_here
      API_PORT: 8040
      API_HOST: 0.0.0.0
      CUDA_VISIBLE_DEVICES: 3
      GPU_MEMORY_FRACTION: 0.4
    ports:
      - "8040:8040"
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 2G
        reservations:
          cpus: "0.25"
          memory: 1G
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
              device_ids: ["3"]
    networks:
      - agent_network
    restart: unless-stopped
    depends_on:
      - base-python

  intelligent-invoicing:
    build:
      context: ./intelligent-invoicing-agent
      dockerfile: Dockerfile
    image: solnai/intelligent-invoicing:latest
    environment:
      API_KEY: your_api_key_here
      API_PORT: 8041
      API_HOST: 0.0.0.0
      CUDA_VISIBLE_DEVICES: 3
      GPU_MEMORY_FRACTION: 0.3
    ports:
      - "8041:8041"
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 2G
        reservations:
          cpus: "0.25"
          memory: 1G
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
              device_ids: ["3"]
    networks:
      - agent_network
    restart: unless-stopped
    depends_on:
      - base-python

  website-redesign:
    build:
      context: ./website-redesign-agent
      dockerfile: Dockerfile
    image: solnai/website-redesign:latest
    environment:
      API_KEY: your_api_key_here
      API_PORT: 8042
      API_HOST: 0.0.0.0
      CUDA_VISIBLE_DEVICES: 3
      GPU_MEMORY_FRACTION: 0.3
    ports:
      - "8042:8042"
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 2G
        reservations:
          cpus: "0.25"
          memory: 1G
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
              device_ids: ["3"]
    networks:
      - agent_network
    restart: unless-stopped
    depends_on:
      - base-python

  ##########################################
  # INTEGRATION & WORKFLOW - GPU: 4
  ##########################################
  
  n8n-integration:
    build:
      context: ./n8n-integration-agent
      dockerfile: Dockerfile
    image: solnai/n8n-integration:latest
    environment:
      API_KEY: your_api_key_here
      API_PORT: 8050
      API_HOST: 0.0.0.0
      CUDA_VISIBLE_DEVICES: 4
      GPU_MEMORY_FRACTION: 0.4
    ports:
      - "8050:8050"
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 2G
        reservations:
          cpus: "0.25"
          memory: 1G
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
              device_ids: ["4"]
    networks:
      - agent_network
    restart: unless-stopped
    depends_on:
      - base-python

  multi-tool-agent:
    build:
      context: ./smart-select-multi-tool-agent
      dockerfile: Dockerfile
    image: solnai/multi-tool-agent:latest
    environment:
      API_KEY: your_api_key_here
      API_PORT: 8051
      API_HOST: 0.0.0.0
      CUDA_VISIBLE_DEVICES: 4
      GPU_MEMORY_FRACTION: 0.3
    ports:
      - "8051:8051"
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 2G
        reservations:
          cpus: "0.25"
          memory: 1G
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
              device_ids: ["4"]
    networks:
      - agent_network
    restart: unless-stopped
    depends_on:
      - base-python

  langgraph-parallel:
    build:
      context: ./pydantic-ai-langgraph-parallelization
      dockerfile: Dockerfile
    image: solnai/langgraph-parallel:latest
    environment:
      API_KEY: your_api_key_here
      API_PORT: 8052
      API_HOST: 0.0.0.0
      CUDA_VISIBLE_DEVICES: 4
      GPU_MEMORY_FRACTION: 0.3
    ports:
      - "8052:8052"
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 2G
        reservations:
          cpus: "0.25"
          memory: 1G
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
              device_ids: ["4"]
    networks:
      - agent_network
    restart: unless-stopped
    depends_on:
      - base-python

  ##########################################
  # CORE/UTILITY AGENTS - GPU: 5
  ##########################################
  
  tinydm-agent:
    build:
      context: ./TinyDM-agent
      dockerfile: Dockerfile
    image: solnai/tinydm-agent:latest
    environment:
      API_KEY: your_api_key_here
      API_PORT: 8002
      API_HOST: 0.0.0.0
      CUDA_VISIBLE_DEVICES: 5
      GPU_MEMORY_FRACTION: 0.4
    ports:
      - "8002:8000"
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 2G
        reservations:
          cpus: "0.25"
          memory: 1G
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
              device_ids: ["5"]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 20s
      timeout: 10s
      retries: 5
      start_period: 40s
    networks:
      - agent_network
    restart: unless-stopped
    depends_on:
      - base-python

  ask-reddit-agent:
    build:
      context: ./ask-reddit-agent
      dockerfile: Dockerfile
    image: solnai/ask-reddit-agent:latest
    environment:
      API_KEY: your_api_key_here
      API_PORT: 8003
      API_HOST: 0.0.0.0
      CUDA_VISIBLE_DEVICES: 5
      GPU_MEMORY_FRACTION: 0.3
      REDDIT_CLIENT_ID: your_reddit_client_id
      REDDIT_CLIENT_SECRET: your_reddit_client_secret
      REDDIT_USER_AGENT: your_user_agent
    ports:
      - "8003:8000"
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 2G
        reservations:
          cpus: "0.25"
          memory: 1G
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
              device_ids: ["5"]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 20s
      timeout: 10s
      retries: 5
      start_period: 40s
    networks:
      - agent_network
    restart: unless-stopped
    depends_on:
      - base-python

  multi-page-scraper:
    build:
      context: ./multi-page-scraper-agent
      dockerfile: Dockerfile
    image: solnai/multi-page-scraper:latest
    environment:
      API_KEY: your_api_key_here
      API_PORT: 8060
      API_HOST: 0.0.0.0
      CUDA_VISIBLE_DEVICES: 5
      GPU_MEMORY_FRACTION: 0.3
    ports:
      - "8060:8060"
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 2G
        reservations:
          cpus: "0.25"
          memory: 1G
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
              device_ids: ["5"]
    networks:
      - agent_network
    restart: unless-stopped
    depends_on:
      - base-python

networks:
  agent_network:
    driver: bridge

volumes:
  postgres_data: {} 